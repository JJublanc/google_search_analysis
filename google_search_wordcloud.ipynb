{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/abenassi/Google-Search-API/blob/master/requirements.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "# Google search queries\n",
    "from google import google\n",
    "\n",
    "# regex package\n",
    "import re\n",
    "\n",
    "# Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('wordcloud_images'):\n",
    "    os.makedirs('wordcloud_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(keyword, num_page = 1):\n",
    "    search_results_descriptions = []\n",
    "    search_results = google.search(keyword, num_page)\n",
    "    \n",
    "    for result in search_results:\n",
    "        search_results_descriptions.append(result.description)\n",
    "    \n",
    "    return search_results_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_string_from_search(keyword,\n",
    "                                 num_page,\n",
    "                                 additionnal_stop_words_list=[\"\\xa0\"],\n",
    "                                 lang=\"french\"):\n",
    "    \n",
    "    # Get resulst of the search\n",
    "    search_results = get_search_results(keyword, num_page)\n",
    "    \n",
    "    # Clean punctuation\n",
    "    long_string = \" \".join(search_results) # transform corpus into a long string\n",
    "    long_string_clean = re.sub('\\xa0', ' ', long_string)\n",
    "    long_string_clean = re.sub(r'[^\\w\\s]', ' ', long_string_clean)\n",
    "    long_string_clean = re.sub('    ', ' ', long_string_clean)\n",
    "    long_string_clean = re.sub('   ', ' ', long_string_clean)\n",
    "    long_string_clean = re.sub('  ', ' ', long_string_clean)\n",
    "    long_string_clean = long_string_clean.lower()\n",
    "\n",
    "    # Transform long string to a list of words\n",
    "    search_words_list = long_string_clean.split(' ')\n",
    "\n",
    "    # Drop stop words\n",
    "    stop_words = stopwords.words(lang) +\\\n",
    "                     additionnal_stop_words_list +\\\n",
    "                     keyword.split(\" \") + [\"\"]\n",
    "\n",
    "    for word in list(stop_words):\n",
    "        search_words_list_stop = [word for word in search_words_list \n",
    "                                  if word not in stop_words]\n",
    "    \n",
    "    \n",
    "    return \" \".join(search_words_list_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(keyword, num_page, folder=\"./wordcloud_images\"):\n",
    "\n",
    "    name = re.sub(' ', '_', keyword) + \"_p\" + str(num_page)\n",
    "    now = datetime.datetime.now().strftime(\"%m_%d_%Y_%Hh%Mm%Ss\")\n",
    "\n",
    "    file_name = name + \"_\" + now +\".png\"\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wordcloud(keyword,\n",
    "                   num_page,\n",
    "                   additionnal_stop_words_list=[\"\\xa0\"],\n",
    "                   lang=\"french\"):\n",
    "\n",
    "    long_string_clean = get_clean_string_from_search(keyword, \n",
    "                                                     num_page,\n",
    "                                                     additionnal_stop_words_list)\n",
    "    file_path = get_file_path(keyword, num_page)\n",
    "\n",
    "    # Create a WordCloud object\n",
    "    wordcloud = WordCloud(background_color=\"white\", \n",
    "                          max_words=5000, \n",
    "                          contour_width=3, contour_color='steelblue')\n",
    "\n",
    "    # Generate a word cloud\n",
    "    wordcloud.generate(long_string_clean)\n",
    "\n",
    "    # Visualize the word cloud\n",
    "    wordcloud.to_file(file_path)\n",
    "    wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"xebia\"\n",
    "num_page = 2\n",
    "additionnal_stop_words_list=[\"\\xa0\",\n",
    "                             \"publicis\",\n",
    "                             \"sapient\"]\n",
    "make_wordcloud(keyword, \n",
    "               num_page, \n",
    "               additionnal_stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"publicis sapient engineering\"\n",
    "num_page = 2\n",
    "additionnal_stop_words_list=[\"\\xa0\",\n",
    "                             \"xebia\"]\n",
    "make_wordcloud(keyword, \n",
    "               num_page, \n",
    "               additionnal_stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"cabinet conseil intelligence artificielle\"\n",
    "num_page = 2\n",
    "additionnal_stop_words_list=[\"\\xa0\"]\n",
    "make_wordcloud(keyword, \n",
    "               num_page, \n",
    "               additionnal_stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"reinforcement learning france\"\n",
    "num_page = 2\n",
    "additionnal_stop_words_list=[\"\\xa0\"]\n",
    "make_wordcloud(keyword, \n",
    "               num_page, \n",
    "               additionnal_stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"natural language processing en france\"\n",
    "num_page = 2\n",
    "additionnal_stop_words_list=[\"\\xa0\"]\n",
    "make_wordcloud(keyword, \n",
    "               num_page, \n",
    "               additionnal_stop_words_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
