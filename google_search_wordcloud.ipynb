{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/abenassi/Google-Search-API/blob/master/requirements.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from google import google\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation du dossier wordcloud_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('wordcloud_images'):\n",
    "    os.makedirs('wordcloud_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(keyword, num_page = 1):\n",
    "    search_results_descriptions = []\n",
    "    search_results = google.search(keyword, num_page)\n",
    "    \n",
    "    for result in search_results:\n",
    "        search_results_descriptions.append(result.description)\n",
    "    \n",
    "    return search_results_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_string_from_search(keyword,\n",
    "                                 num_page,\n",
    "                                 additionnal_stop_words_list=[\"\\xa0\"],\n",
    "                                 lang=\"french\"):\n",
    "    \n",
    "    # Get resulst of the search\n",
    "    search_results = get_search_results(keyword, num_page)\n",
    "    \n",
    "    # Clean punctuation\n",
    "    long_string = \" \".join(search_results) # transform corpus into a long string\n",
    "    long_string_clean = re.sub('\\xa0', ' ', long_string)\n",
    "    long_string_clean = re.sub(r'[^\\w\\s]', ' ', long_string_clean)\n",
    "    long_string_clean = re.sub('    ', ' ', long_string_clean)\n",
    "    long_string_clean = re.sub('   ', ' ', long_string_clean)\n",
    "    long_string_clean = re.sub('  ', ' ', long_string_clean)\n",
    "    long_string_clean = long_string_clean.lower()\n",
    "\n",
    "    # Transform long string to a list of words\n",
    "    search_words_list = long_string_clean.split(' ')\n",
    "\n",
    "    # Drop stop words\n",
    "    stop_words = stopwords.words(lang) +\\\n",
    "                     additionnal_stop_words_list +\\\n",
    "                     keyword.split(\" \") + [\"\"]\n",
    "\n",
    "    for word in list(stop_words):\n",
    "        search_words_list_stop = [word for word in search_words_list \n",
    "                                  if word not in stop_words]\n",
    "    \n",
    "    \n",
    "    return \" \".join(search_words_list_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(keyword, num_page, folder=\"./wordcloud_images\"):\n",
    "\n",
    "    name = re.sub(' ', '_', keyword) + \"_p\" + str(num_page)\n",
    "    now = datetime.datetime.now().strftime(\"%m_%d_%Y_%Hh%Mm%Ss\")\n",
    "\n",
    "    file_name = name + \"_\" + now +\".png\"\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wordcloud(keyword,\n",
    "                   num_page,\n",
    "                   mask,\n",
    "                   additionnal_stop_words_list,\n",
    "                   lang=\"french\"):\n",
    "\n",
    "    long_string_clean = get_clean_string_from_search(keyword, \n",
    "                                                     num_page,\n",
    "                                                     additionnal_stop_words_list)\n",
    "    file_path = get_file_path(keyword, num_page)\n",
    "    \n",
    "    if mask :\n",
    "        path=os.getcwd()\n",
    "        mask = np.array(Image.open(os.path.join(path,\"mask\", mask)))\n",
    "\n",
    "    # Create a WordCloud object\n",
    "    wordcloud = WordCloud(background_color=\"white\",\n",
    "                          max_words=5000, \n",
    "                          contour_width=3, \n",
    "                          contour_color='steelblue',\n",
    "                          width=2400,\n",
    "                          height=1200,\n",
    "                          mask=mask)\n",
    "\n",
    "    # Generate a word cloud\n",
    "    wordcloud.generate(long_string_clean)\n",
    "\n",
    "    # Visualize the word cloud\n",
    "    wordcloud.to_file(file_path)\n",
    "    wordcloud.to_image()\n",
    "    \n",
    "    return wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud(cloud):\n",
    "    \n",
    "    cloud_array = cloud.to_array()\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(cloud_array)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_wordcloud(word, additionnal_stop_words_list, num_page=1, mask=None):\n",
    "\n",
    "    cloud = make_wordcloud(keyword=word, \n",
    "                   num_page=num_page, \n",
    "                   additionnal_stop_words_list=additionnal_stop_words_list,\n",
    "                   mask=mask)\n",
    "\n",
    "    plot_wordcloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_wordcloud(word=\"xebia\",\n",
    "                 additionnal_stop_words_list=[\"\\xa0\", \"publicis\", \"sapient\"],\n",
    "                 num_page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_wordcloud(word=\"publicis sapient engineering\",\n",
    "                 additionnal_stop_words_list=[\"\\xa0\", \"xebia\"],\n",
    "                 num_page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_wordcloud(word=\"cabinet conseil intelligence artificielle\",\n",
    "                 additionnal_stop_words_list=[\"\\xa0\"],\n",
    "                 num_page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_wordcloud(word=\"reinforcement learning france\",\n",
    "                 additionnal_stop_words_list=[\"\\xa0\"],\n",
    "                 num_page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_wordcloud(word=\"natural language processing en france\",\n",
    "                 additionnal_stop_words_list=[\"\\xa0\"],\n",
    "                 num_page=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
